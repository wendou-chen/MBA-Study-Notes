"""GitHub å‘¨çƒ­æ¦œ â€” æ¯å‘¨æŠ“å–çƒ­é—¨é¡¹ç›®å¹¶ç”Ÿæˆä¸­æ–‡æ‘˜è¦ï¼Œå†™å…¥ Obsidian ç¬”è®°ã€‚"""

import os
import sys
import time
import base64
from datetime import datetime, timedelta
from pathlib import Path

import anthropic
import requests

SCRIPT_DIR = Path(__file__).resolve().parent.parent.parent.parent.parent  # vault root
OUTPUT_DIR = SCRIPT_DIR / "GitHubå‘¨åˆŠ"
DEFAULT_BASE_URL = os.getenv("ANTHROPIC_BASE_URL", "https://api.anthropic.com")
MODEL = "claude-sonnet-4-5-20250929"
GITHUB_API = "https://api.github.com"

# æŸ¥è¯¢åˆ†ç±»é…ç½®
CATEGORIES = [
    {
        "name": "ğŸ”¥ å…¨å±€çƒ­æ¦œ",
        "query_extra": "",
        "min_stars": 100,
        "count": 5,
        "deep_summary": True,
    },
    {
        "name": "ğŸ¤– AI / æœºå™¨å­¦ä¹ ",
        "query_extra": "topic:machine-learning OR topic:deep-learning OR topic:llm",
        "min_stars": 30,
        "count": 5,
        "deep_summary": False,
    },
    {
        "name": "ğŸ“¡ ä¿¡å·å¤„ç† / é€šä¿¡",
        "query_extra": "topic:signal-processing OR topic:communications OR topic:wireless OR language:matlab",
        "min_stars": 5,
        "count": 2,
        "deep_summary": False,
    },
    {
        "name": "ğŸ Python å·¥å…·",
        "query_extra": "language:python",
        "min_stars": 50,
        "count": 3,
        "deep_summary": False,
    },
]

SUMMARY_PROMPT = """\
ä½ æ˜¯ä¸€ä½æŠ€æœ¯è¶‹åŠ¿åˆ†æå¸ˆã€‚è¯·ç”¨ä¸­æ–‡ä¸ºä»¥ä¸‹ GitHub é¡¹ç›®å†™ä¸€æ®µç®€ä»‹ï¼ˆ3-5 å¥ï¼‰ï¼Œé‡ç‚¹å…³æ³¨ï¼š
1. **é¡¹ç›®å®šä½**ï¼šè§£å†³ä»€ä¹ˆé—®é¢˜ï¼Ÿé¢å‘ä»€ä¹ˆç”¨æˆ·ï¼Ÿ
2. **æŠ€æœ¯äº®ç‚¹**ï¼šæ ¸å¿ƒæŠ€æœ¯æ ˆæˆ–åˆ›æ–°ç‚¹
3. **è€ƒç ”å­¦ç”Ÿè§†è§’**ï¼šå¯¹é€šä¿¡/ç”µå­æ–¹å‘ç ”ç©¶ç”Ÿæœ‰ä»€ä¹ˆå‚è€ƒä»·å€¼ï¼Ÿ

è¯·ç”¨ Markdown æ ¼å¼è¾“å‡ºï¼Œç®€æ´ä¸“ä¸šã€‚

é¡¹ç›®ï¼š{full_name}
æè¿°ï¼š{description}
è¯­è¨€ï¼š{language}
README ç‰‡æ®µï¼š
{readme}"""

TRANSLATE_PROMPT = """\
å°†ä»¥ä¸‹ GitHub é¡¹ç›®æè¿°ç¿»è¯‘ä¸ºç®€æ´çš„ä¸­æ–‡ï¼ˆä¸€å¥è¯ï¼‰ã€‚å¦‚æœå·²ç»æ˜¯ä¸­æ–‡åˆ™åŸæ ·è¿”å›ã€‚

æè¿°ï¼š{description}"""


def load_env():
    """ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆå¤ç”¨ daily_paper.py é€»è¾‘ï¼‰ã€‚"""
    env_path = SCRIPT_DIR / ".env"
    if env_path.exists():
        with open(env_path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith("#") and "=" in line:
                    key, value = line.split("=", 1)
                    os.environ.setdefault(key.strip(), value.strip())

    if "ANTHROPIC_API_KEY" not in os.environ:
        print("é”™è¯¯ï¼šæœªæ‰¾åˆ° ANTHROPIC_API_KEYï¼Œè¯·åœ¨ .env ä¸­é…ç½®ã€‚", file=sys.stderr)
        sys.exit(1)

    if "GITHUB_TOKEN" not in os.environ:
        print("æç¤ºï¼šæœªé…ç½® GITHUB_TOKENï¼Œå°†ä»¥åŒ¿åæ¨¡å¼è®¿é—® GitHub APIï¼ˆé™é€Ÿ 10 æ¬¡/åˆ†é’Ÿï¼‰ã€‚")


def _github_headers() -> dict:
    """æ„å»º GitHub API è¯·æ±‚å¤´ã€‚"""
    headers = {"Accept": "application/vnd.github.v3+json"}
    token = os.environ.get("GITHUB_TOKEN")
    if token:
        headers["Authorization"] = f"token {token}"
    return headers


def fetch_trending(query_extra: str, min_stars: int, count: int,
                   since_date: str) -> list[dict]:
    """é€šè¿‡ GitHub Search API è·å–çƒ­é—¨ä»“åº“ã€‚"""
    q = f"created:>{since_date} stars:>={min_stars}"
    if query_extra:
        q += f" {query_extra}"

    url = f"{GITHUB_API}/search/repositories"
    params = {"q": q, "sort": "stars", "order": "desc", "per_page": count}

    try:
        resp = requests.get(url, headers=_github_headers(), params=params, timeout=15)
        if resp.status_code == 403:
            print(f"  âš ï¸ GitHub API é™é€Ÿï¼Œè·³è¿‡æ­¤åˆ†ç±»ã€‚")
            return []
        if resp.status_code == 422:
            print(f"  âš ï¸ GitHub API æŸ¥è¯¢æ— æ•ˆï¼ˆ422ï¼‰ï¼Œè·³è¿‡æ­¤åˆ†ç±»ã€‚")
            return []
        resp.raise_for_status()
        return resp.json().get("items", [])
    except requests.RequestException as e:
        print(f"  âš ï¸ GitHub API è¯·æ±‚å¤±è´¥ï¼š{e}")
        return []


def fetch_readme_snippet(full_name: str, max_chars: int = 500) -> str:
    """è·å–ä»“åº“ README å‰ N ä¸ªå­—ç¬¦ï¼ˆç”¨äºå…¨å±€çƒ­æ¦œæ·±åº¦æ‘˜è¦ï¼‰ã€‚"""
    url = f"{GITHUB_API}/repos/{full_name}/readme"
    try:
        resp = requests.get(url, headers=_github_headers(), timeout=10)
        if resp.status_code != 200:
            return ""
        content = resp.json().get("content", "")
        decoded = base64.b64decode(content).decode("utf-8", errors="replace")
        return decoded[:max_chars]
    except Exception:
        return ""


def summarize(client: anthropic.Anthropic, repo: dict, readme: str) -> str:
    """è°ƒç”¨ Claude API ç”Ÿæˆæ·±åº¦ä¸­æ–‡æ‘˜è¦ï¼ˆå…¨å±€çƒ­æ¦œç”¨ï¼‰ã€‚"""
    try:
        resp = client.messages.create(
            model=MODEL,
            max_tokens=512,
            messages=[{
                "role": "user",
                "content": SUMMARY_PROMPT.format(
                    full_name=repo["full_name"],
                    description=repo.get("description") or "æ— æè¿°",
                    language=repo.get("language") or "æœªçŸ¥",
                    readme=readme or "ï¼ˆæ—  READMEï¼‰",
                ),
            }],
        )
        return resp.content[0].text
    except Exception as e:
        return f"âš ï¸ æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼š{e}"


def translate_description(client: anthropic.Anthropic, description: str) -> str:
    """è°ƒç”¨ Claude API å°†æè¿°ç¿»è¯‘ä¸ºä¸­æ–‡ï¼ˆè½»é‡ç¿»è¯‘ï¼‰ã€‚"""
    if not description:
        return "æ— æè¿°"
    # ç®€å•æ£€æµ‹ï¼šå¦‚æœå·²å«å¤§é‡ä¸­æ–‡å­—ç¬¦åˆ™è·³è¿‡ç¿»è¯‘
    cn_chars = sum(1 for c in description if "\u4e00" <= c <= "\u9fff")
    if cn_chars > len(description) * 0.3:
        return description
    try:
        resp = client.messages.create(
            model=MODEL,
            max_tokens=128,
            messages=[{
                "role": "user",
                "content": TRANSLATE_PROMPT.format(description=description),
            }],
        )
        return resp.content[0].text.strip()
    except Exception:
        return description


def format_table_row(idx: int, repo: dict, desc_cn: str) -> str:
    """æ ¼å¼åŒ–å•ä¸ªä»“åº“ä¸ºè¡¨æ ¼è¡Œã€‚"""
    stars = f"{repo['stargazers_count']:,}"
    lang = repo.get("language") or "â€”"
    name = repo["full_name"]
    url = repo["html_url"]
    return f"| {idx} | [{name}]({url}) | {stars} | {lang} | {desc_cn} |"


def format_summary_callout(repo: dict, summary: str) -> str:
    """æ ¼å¼åŒ– AI æ·±åº¦æ‘˜è¦ä¸º Obsidian calloutã€‚"""
    summary_lines = "\n".join(f"> {line}" for line in summary.split("\n"))
    return f"""\n> [!tip] AI ç®€ä»‹ï¼š{repo['full_name']}
{summary_lines}
"""


def format_section(category_name: str, repos: list[dict],
                   descriptions: list[str],
                   summaries: list[str] | None = None) -> str:
    """æ ¼å¼åŒ–å®Œæ•´åˆ†ç±»æ®µè½ã€‚"""
    desc_col = "æè¿°" if summaries else "ä¸­æ–‡æè¿°"
    lines = [
        f"## {category_name}",
        "",
        f"| # | é¡¹ç›® | â­ Stars | è¯­è¨€ | {desc_col} |",
        "|---|------|---------|------|------|",
    ]
    for i, (repo, desc) in enumerate(zip(repos, descriptions), 1):
        lines.append(format_table_row(i, repo, desc))

    if summaries:
        lines.append("")
        for repo, summary in zip(repos, summaries):
            lines.append(format_summary_callout(repo, summary))

    lines.append("\n---\n")
    return "\n".join(lines)


def write_weekly_file(sections: list[str], week_start: str, week_end: str,
                      repo_count: int):
    """å†™å…¥å‘¨åˆŠæ–‡ä»¶ã€‚å·²å­˜åœ¨åˆ™è·³è¿‡ã€‚"""
    OUTPUT_DIR.mkdir(exist_ok=True)
    filepath = OUTPUT_DIR / f"{week_start}~{week_end}.md"

    if filepath.exists():
        print(f"æœ¬å‘¨å‘¨åˆŠå·²å­˜åœ¨ï¼Œè·³è¿‡å†™å…¥ï¼š{filepath}")
        return

    frontmatter = f"""---
date: {week_end}
tags: [github-weekly, tech-trends]
week_range: {week_start} ~ {week_end}
repo_count: {repo_count}
---

# GitHub å‘¨çƒ­æ¦œ {week_start} ~ {week_end}

> [!info] æœ¬å‘¨æ¦‚è§ˆ
> å…±æ”¶å½• **{repo_count}** ä¸ªçƒ­é—¨é¡¹ç›®ï¼Œè¦†ç›–å…¨å±€çƒ­æ¦œã€AI/MLã€ä¿¡å·å¤„ç†/é€šä¿¡ã€Python å·¥å…·å››ä¸ªæ–¹å‘ã€‚

---

"""
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(frontmatter)
        f.write("\n".join(sections))
    print(f"å·²åˆ›å»º {filepath}")


def main():
    load_env()

    today = datetime.now()
    # è®¡ç®—æœ¬å‘¨ä¸€åˆ°ä»Šå¤©çš„æ—¥æœŸèŒƒå›´
    week_start = (today - timedelta(days=today.weekday())).strftime("%Y-%m-%d")
    week_end = today.strftime("%Y-%m-%d")
    since_date = week_start

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    OUTPUT_DIR.mkdir(exist_ok=True)
    filepath = OUTPUT_DIR / f"{week_start}~{week_end}.md"
    if filepath.exists():
        print(f"æœ¬å‘¨å‘¨åˆŠå·²å­˜åœ¨ï¼Œè·³è¿‡ï¼š{filepath}")
        return

    print(f"GitHub å‘¨çƒ­æ¦œ {week_start} ~ {week_end}")
    print("=" * 50)

    ai_client = anthropic.Anthropic(
        api_key=os.environ["ANTHROPIC_API_KEY"],
        base_url=os.environ.get("ANTHROPIC_BASE_URL", DEFAULT_BASE_URL),
    )

    seen: set[str] = set()
    sections: list[str] = []
    total_count = 0

    for cat in CATEGORIES:
        print(f"\næ­£åœ¨è·å–ï¼š{cat['name']}...")
        repos = fetch_trending(cat["query_extra"], cat["min_stars"],
                               cat["count"] + 5, since_date)
        # å»é‡å¹¶æˆªå–
        unique_repos = []
        for repo in repos:
            if repo["full_name"] not in seen:
                seen.add(repo["full_name"])
                unique_repos.append(repo)
            if len(unique_repos) >= cat["count"]:
                break

        if not unique_repos:
            print(f"  æ— ç»“æœï¼Œè·³è¿‡ã€‚")
            continue

        print(f"  æ‰¾åˆ° {len(unique_repos)} ä¸ªé¡¹ç›®ï¼Œæ­£åœ¨å¤„ç†...")
        descriptions = []
        summaries = [] if cat["deep_summary"] else None

        for i, repo in enumerate(unique_repos, 1):
            desc = repo.get("description") or ""
            print(f"  [{i}/{len(unique_repos)}] {repo['full_name']}")

            if cat["deep_summary"]:
                readme = fetch_readme_snippet(repo["full_name"])
                summary = summarize(ai_client, repo, readme)
                summaries.append(summary)
                descriptions.append(desc[:80] if desc else "æ— æè¿°")
                time.sleep(0.5)  # é¿å… API é™é€Ÿ
            else:
                desc_cn = translate_description(ai_client, desc)
                descriptions.append(desc_cn)
                time.sleep(0.3)

        sections.append(format_section(cat["name"], unique_repos,
                                       descriptions, summaries))
        total_count += len(unique_repos)

    if not sections:
        print("æ‰€æœ‰åˆ†ç±»å‡æ— ç»“æœã€‚")
        return

    write_weekly_file(sections, week_start, week_end, total_count)
    print(f"\nå®Œæˆï¼å…±æ”¶å½• {total_count} ä¸ªé¡¹ç›®ã€‚")


if __name__ == "__main__":
    main()
